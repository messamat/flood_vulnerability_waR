library(sf)
library(data.table)
library(plyr)
library(ggplot2)
library(RColorBrewer)
library(gridExtra)
library(ggrepel)
library(stringr)
library(extrafont)
library(hrbrthemes)
library(VennDiagram)
library(ggtern)
library(kableExtra)
library(compositions)
library(lme4)
library(nlme)
library(gamlss)
library(gamlss.dist)
library(ggeffects)
library(feather)

if (grepl('results', getwd())) {
  rootdir =  "C:/Mathis/ICSL/flood_vulnerability"
} else{
  rootdir = gsub("/src.*","",getwd())
}
datadir = file.path(rootdir, 'data')
resdir = file.path(rootdir, 'results')
figdir = file.path(resdir, 'figures')
setwd(resdir)

#+----------------------------------- Define functions ------------------------------------------------
#Compute percentages for each race for a given model
summod <- function(dt, mod, ref, byc=NULL) {
  races <- unique(gsub(paste0('_',mod,'.*'), '',
                       grep(mod, colnames(dt), value=T)))
  ldply(races, function(race) {
    popcol = grep(paste0(race, '.*', mod, '.*_pop$'), colnames(p_attri), value=T)
    floodcol = grep(paste0(race, '.*', mod, '.*_popflood$'), colnames(p_attri), value=T)
    femacol = grep(paste0(race, '.*', mod, '.*_popFEMA$'), colnames(p_attri), value=T)
    varn <- c('per','floodper','FEMAper')
    statsdt <- p_attri[, c(sum(get(popcol), na.rm=T)/sum(get(paste0(ref, '_pop')), na.rm=T),
                           sum(get(floodcol), na.rm=T)/sum(get(paste0(ref, '_popflood')), na.rm=T),
                           sum(get(femacol), na.rm=T)/sum(get(paste0(ref, '_popfema')), na.rm=T)), by=byc]
    if (is.null(byc)) {
      statsdt <- data.table(bycol=rep('total', length(statsdt)), statsdt)
    }
    statsdt <- cbind(varn, statsdt, race, mod)
    paste0(race,'_',mod,'per')
    return(setDT(statsdt))
  })
}

#Build function for basic multiplot with weighted mean and quantile regression
multiplot <- function(dat, xvar, yvar, weightvar, facetvar) {
  p <- ggplot(dat, aes_string(x=xvar, y=yvar)) + 
    geom_point(alpha=1/4) + 
    geom_smooth(color='red', method='lm', aes_string(weight = weightvar)) +
    geom_quantile(quantiles=c(0.1, 0.25, 0.5, 0.75, 0.9), color='orange',
                  aes_string(mapping = weightvar)) +
    scale_y_log10() +
    geom_hline(yintercept=1, color='blue') +
    facet_wrap(as.formula(paste('~',facetvar)), scales = 'free_x') +
    theme_classic() +
    theme(axis.title =element_text(size=16),
          strip.text = element_text(size=16),
          strip.background = element_rect(colour="white"),
          text = element_text(size=16))
  print(p)
}

#Create new data for every combination of probabilities from Nstep
newprobmat <- function(step) {
  matlen <- (5*20/step+1)*(5*20/step+2)*(5*20/step+3)*(5*20/step+4)/24 #tweak on https://oeis.org/A151989 (20 coming from 100/5 loops)
  #Can also be written Reduce('*', (ncols*nvalues/step+seq_len(ncol-1)))/24
  
  predmat <- matrix(NA, matlen, 5)
  x=1
  for (i in seq(0L,100L, as.integer(step))) {
    for (j in seq(0L,100L-i, as.integer(step))) {
      for (k in seq(0L,100L-(i+j), as.integer(step))) {
        for (l in seq(0L,100L-(i+j+k), as.integer(step))) {
          predmat[x,] <- c(i,j,k,l,100-(i+j+k+l))
          x=x+1
        }
      }
    }
  }
  return(predmat)
}

#+----------------------------------- Import data ------------------------------------------------
gdb <- 'flood_risk.gdb'
# #Read parcel-level data 
# p_attri <- st_read(dsn=gdb,layer="parcel_blocks_fill_flood_attri")
# p_attri <- setDT(p_attri)
# p_attri <- p_attri[FEMAFloodStatus == 1 & is.na(FEMAStudyStatus), FEMAFloodStatus := 0]
# p_attri <- p_attri[is.na(FEMAStudyStatus), FEMAStudyStatus := 0]
# 
# #Read census trast-level data
t_attri <- st_read(dsn=gdb, layer="tracts_floodfinal")
t_attri <- setDT(t_attri)
t_attri[, county := as.factor(substr(GEOID10_t, 1, 5))]
# 
# save.image(file = "flood_vulnerability_model_dataimport.RData")
load(file = "C:/Mathis/ICSL/flood_vulnerability/results/flood_vulnerability_model_dataimport.RData")
p_attri <- p_attri[t_attri[,c('GEOID10_t', 'DP0230001'), with=F], on='GEOID10_t'] #Add average household size
p_attri[, county := as.factor(substr(GEOID10_t, 1, 5))]

#Export data for Jamie's presentation
p_attrisub_pierce <- p_attri[county == '53053', 
                          .(BuildNum, PolyID, HOUSINGADJ, PARCELPOP,
                            white_BISG_pop, hisp_BISG_pop, black_BISG_pop, asi_BISG_pop, oth_BISG_pop)]
write.csv(p_attrisub_pierce, 'parcel_attributes_pierce_forJamie20190122.csv') #In ArcGIS, make a quick right-join on parcel polygons

#Block group data
bg <- st_read(file.path(datadir, 'TIGER2017/2010_ACS_5YR_BG_53_WASHINGTON.gdb'), layer = 'ACS_10_5YR_BG_53_WASHINGTON')
bg[, county := as.factor(substr(GEOID10, 1, 5))]

#+------------- Format data for block-group level analysis --------------------------------------------------------------
# poverty status B17021e1
# median household income B19013e1
# owner-occupied housing units median value (B25077e1)
# ratio of income to poverty level in past 12 months (C17002e1)
# contract rent/with cash rent (B25056e2)

#Compute percentage population flooded within each block group
wastats_bgsub <- bg[p_attri[, list(parcelfloodper = sum(floodpop)/sum(PARCELPOP)), by='GEOID10_bg'], on='GEOID10==GEOID10_bg']

#Compute average of state-standardized rent and house prise
wastats_bgsub[, `:=`(housing_standardized = B25077e1/mean(B25077e1, na.rm = T),
                   rent_standardized = B25056e2/mean(B25056e2, na.rm = T))][
                     , real_standardized := rowMeans(cbind(housing_standardized, rent_standardized), na.rm=T)]
#Compute average of county-standardized rent and house price
wastats_bgsub[, `:=`(B25077e1_countymean = mean(B25077e1, na.rm = T),
                     B25056e2_countymean = mean(B25056e2, na.rm = T)),
              by=county][
                , `:=`(housing_countystandardized = B25077e1/B25077e1_countymean,
                       rent_countystandardized = B25056e2/B25056e2_countymean),
              ][
                , real_countystandardized := rowMeans(cbind(housing_countystandardized, rent_countystandardized), na.rm=T)
              ]
  

#Format data for beta-inflated regression model
qplot(wastats_bgsub$parcelfloodper)
summary(wastats_bgsub$parcelfloodper)
which(wastats_bgsub$parcelfloodper < 0)
check1 <- wastats_bgsub[parcelfloodper > 1,]
wastats_bgsub[parcelfloodper > 1, parcelfloodper := 1]

#Get block-group percentage flooded population numbers
wastats_bg <- setDT(summod(p_attri, mod='BISG', 'last', byc='GEOID10_bg'))
wastats_bgcast <- dcast(wastats_bg, GEOID10_bg~varn+race, value.var = 'V1') %>%
  .[wastats_bgsub, on='GEOID10_bg==GEOID10']
BISG_colsbg <- c("per_asi", "per_black", "per_hisp", "per_white" , "per_oth")

#Round data based on smallest values
colSums(wastats_bgcast == 0, na.rm=T) #Check number of 0s in each column
wastats_bgcast[!is.na(per_asi), sapply(.SD, function(x) min(ifelse(x>0, x, NA), na.rm=T)), .SDcols = BISG_colsbg] #Check smallest value in each column
wastats_bgcast[, (BISG_colsbg) := round(.SD, 6), .SDcols = BISG_colsbg]

#Make sure that race-ethnicity probability vector only sums to 0-1
table(wastats_bgcast[, Reduce('+', .SD), .SDcols = BISG_colsbg]) 
wastats_bgcast[, sum_BISG := Reduce('+', .SD), .SDcols = BISG_colsbg]
wastats_bgcast[sum_BISG > 0, per_oth := per_oth + 1 - sum_BISG] 

#Deal with 0s by replacing them all by 10-6 through multiplicative imputation 
wastats_bgcast[sum_BISG > 0, (BISG_colsbg) := lapply(.SD, function(x){x[x==0] <- 10^(-6); x}), .SDcols = BISG_colsbg]
wastats_bgcast[, sum_BISG := Reduce('+', .SD), .SDcols = BISG_colsbg]
BISG_colsbgclo <- paste0(BISG_colsbg,"_clo")
wastats_bgcast[sum_BISG > 0, (BISG_colsbgclo) := lapply(.SD, `/`, sum_BISG), .SDcols = BISG_colsbg]
table(wastats_bgcast[, Reduce('+', .SD), .SDcols = BISG_colsbgclo]) #Make sure that add up to 1

#Univariate histogram
colpal <- brewer.pal(n = length(BISG_colsbgclo), name="Set2")
uniBISG <- sapply(BISG_colsbgclo, function(cvar) {
  ggplotGrob(ggplot(wastats_bgcast, aes_string(x=cvar)) +
               geom_density(fill = colpal[which(BISG_colsbgclo == cvar)]) +
               scale_x_continuous(expand=c(0,0), name=cvar) +
               scale_y_sqrt() +
               theme_classic()
  )
})
do.call("grid.arrange", uniBISG)

#Make ternary density plots
ternmatrix_l <- sapply(seq_len(length(BISG_colsbgclo)-2), function(i) {
  sapply(seq(2, length(BISG_colsbgclo)-1), function(j) {
    if (i != j) {
      xpc <- BISG_colsbgclo[i]
      ypc <- BISG_colsbgclo[j]
      wastats_bgcast[!(sum_BISG %in% c(0, NA)), tern_oth_BISG := Reduce(`+`, .SD), .SDcols = BISG_colsbgclo[-c(i, j)]]
      nr <- nrow(wastats_bgcast[!(sum_BISG %in% c(0, NA)),]) 
      samp <- wastats_bgcast[!(sum_BISG %in% c(0, NA)),]#[sample(nr, nr/3),]no sampling for bg
      ggplotGrob(
        ggtern(data=samp,aes(get(xpc),get(ypc),tern_oth_BISG)) + 
          stat_density_tern(geom='polygon', aes(fill=..level..), bins=30, color=NA) + 
          scale_fill_distiller(palette='Spectral') + 
          theme(legend.position = 'none') +
          labs( x       = paste(gsub('per_', '', gsub('_clo', '', xpc)), '%'),
                xarrow  = paste(gsub('per_', '', gsub('_clo', '', xpc)), '%'),
                y       = paste(gsub('per_', '', gsub('_clo', '', ypc)), '%'),
                yarrow  = paste(gsub('per_', '', gsub('_clo', '', ypc)), '%'),
                z       = "Other",
                zarrow  = "Other") +
          theme_showarrows() + 
          theme_clockwise()
      )
    } 
  })
})  
do.call("grid.arrange", list(grobs=ternmatrix_l[lower.tri(ternmatrix_l, diag=T)], 
                             ncol=nrow(ternmatrix_l))) #only keep unique combinations

#Create compositional data
BISGcomp_bg <- acomp(wastats_bgcast[!(sum_BISG %in% c(0, NA)), .SD, .SDcols = BISG_colsbgclo])


# ---- Fit null model ----
nullmod <- gamlss(parcelfloodper ~ county,
                  nu.formula=~county, 
                  sigma.formula=~county,
                  family=BEINF,  #Very 0- and 1- inflated beta distribution
                  data= wastats_bgcast[!(is.na(get(BISG_colsbgclo[1])) | is.na(county)), 
                                       .(parcelfloodper, county)])
summary(nullmod)
AIC(nullmod)

# ---- Fit model % flooded parcels ~ real estate index and median household income ----
"See A8.2 p195 of gamlss manual of model description.
mu is the mean of the beta model, sigma is the shape, nu is the probability ratio of p==0 and tau is the probability ratio of p==1"
check2 <- wastats_bgsub[is.na(parcelfloodper) | is.na(real_standardized),] #Only those that have no population
wastats_bgsub[!(is.na(parcelfloodper) | is.na(real_standardized)), 
              .N, by=county]

modat <- wastats_bgsub[!(is.na(parcelfloodper) | is.na(real_standardized) | is.na(B19013e1)), 
                       .(parcelfloodper, real_standardized, B19013e1, county),]
bg_real1 <- gamlss(parcelfloodper ~ real_standardized + B19013e1 + county,
                   nu.formula=~real_standardized + B19013e1 + county, 
                   sigma.formula=~real_standardized  + B19013e1 + county,
                   family=BEINF,  #Very 0- and 1- inflated beta distribution
                   data= modat)
summary(bg_real1)
plot(bg_real1)

wastats_bgsub[!(is.na(parcelfloodper) | is.na(real_standardized)| is.na(B19013e1)), real1_fit := meanBEINF(bg_real1)] 
ggplot(wastats_bgsub, aes(x=real1_fit, y=parcelfloodper)) +
  geom_point() +
  geom_smooth(method='lm')


ggplot(wastats_bgsub[!(is.na(parcelfloodper) | is.na(real_standardized)| is.na(B19013e1)),]
       , aes(x=real_standardized, y=real1_fit, color=county)) +
  geom_point() +
  geom_smooth(method='gam')

pfunc <- getPEF(obj=bg_real1,term="B19013e1", plot=TRUE, type='response', how='median')
pfunc(10000)
getPEF(obj=bg_real1,term="real_standardized", plot=TRUE, type='response', how='median')

# ---- Fit model % flooded parcels ~ isometric log-ratio transformed race composition ----
ilrcols <- paste0('ilr', seq_len(ncol(BISGcomp_bg)-1))
wastats_bgcast[!(sum_BISG %in% c(0, NA)), (ilrcols) := as.data.frame(ilr(BISGcomp_bg))]
modat <- as.data.frame(wastats_bgcast[!(sum_BISG %in% c(0, NA) | is.na(county)),
                                      c('parcelfloodper', 'county', ilrcols), with=F])
bg_ilr1 <- gamlss(parcelfloodper ~ ilr1 + ilr2 + ilr3 + ilr4 + county,
                  #sigma.formula = county,
                  nu.formula=~ilr1 + ilr2 + ilr3 + ilr4 + county, 
                  tau.formula=~ilr1 + ilr2 + ilr3 + ilr4 + county,
                  family=BEINF,  #Very 0- and 1- inflated beta distribution
                  data= modat)
summary(bg_ilr1) #Sometimes just doesn't work
plot(bg_ilr1)

wastats_bgcast[!(sum_BISG %in% c(0, NA)), ilr1_fit := meanBEINF(bg_ilr1)] 
ggplot(wastats_bgcast, aes(x=ilr1_fit, y=parcelfloodper)) +
  geom_point() +
  geom_smooth(method='lm')

ggplot(wastats_bgcast, aes(x=per_white, y=parcelfloodper, color=county)) +
  geom_point() +
  facet_grid(~county) +
  geom_smooth(method='gam', span=1)

#Ternary diagram of predictions
predmat_bg <- newprobmat(5)
#Add 10^06 to 0s and perform multiplicative reclosure
predmat_bg <- (predmat_bg/100+10^-6)/rowSums(predmat_bg/100+10^-6)
predmat_bgformat <- cbind(predmat_bg, as.data.frame(ilr(acomp(predmat_bg))))
colnames(predmat_bgformat) <- c(BISG_colsbgclo, ilrcols)
predmat_bgformat$county <- as.factor(53077)


predmat_bgformat$ilr1_fit <- predict(bg_ilr1, newdata=predmat_bgformat[, -seq_len(length(BISG_colsbgclo))])

setDT(predmat_bgformat)[, tern_oth_BISG := Reduce(`+`, .SD), 
                 .SDcols = BISG_colsbgclo[!(BISG_colsbgclo %in% c('per_white_clo', 'per_hisp_clo'))]]
xpc <- 'per_white_clo'
ypc <- 'per_hisp_clo'
ggtern(data=predmat_bgformat,aes(get(xpc),get(ypc),tern_oth_BISG)) + 
  geom_point(aes(color=ilr1_fit)) +
  facet_wrap(~county) +
  #stat_density_tern(geom='polygon', aes(fill=mean(ilr1_fit)), bins=30, color=NA) + 
  #scale_fill_distiller(palette='Spectral') + 
  scale_color_distiller(palette='Spectral') + 
  theme(legend.position = 'none') +
  labs( x       = paste(gsub('per_', '', gsub('_clo', '', xpc)), '%'),
        xarrow  = paste(gsub('per_', '', gsub('_clo', '', xpc)), '%'),
        y       = paste(gsub('per_', '', gsub('_clo', '', ypc)), '%'),
        yarrow  = paste(gsub('per_', '', gsub('_clo', '', ypc)), '%'),
        z       = "Other",
        zarrow  = "Other") +
  theme_showarrows() + 
  theme_clockwise()




getPEF(obj=bg_ilr1, term="ilr4", plot=TRUE, type='response', how='median')
bg_ilr1$nu.coefficients

  
  
#+------------- tract-based regression analysis -------------
tBISG_cols <- c("white_BISG_per", "black_BISG_per", "hisp_BISG_per", "asi_BISG_per", "oth_BISG_per")
colnames(t_attri)
#Check distribution of percentage population within flood zone
t_attri[, .N, by='county']
ggplot(t_attri, aes(x=parcelfloodper)) + 
  geom_histogram() +
  facet_wrap(~county, scales='free_y')

#Make ternary racial composition distribution plots

#Make compositional data series

#Model


#Initial easy fixed effect model with average household size:
# --- % flooded population: zero-inflated zero regression
# --- Fixed effect (for now): average household size
# --- Random effect: county or watershed
ggplot(t_attri, aes(x=DP0230001, y=parcelfloodper)) + 
  geom_point() +
  geom_smooth() 

check <- t_attri[is.na(parcelfloodper) | is.na(DP0230001),] #Only those that have no population
housesize1 <- gamlss(parcelfloodper ~ re(random=~1|county), #DP0230001 + 
                     family=BEINF,  #Very 0- and 1- inflated beta distribution
                     data=t_attri[!(is.na(parcelfloodper) | is.na(DP0230001)) & DP0230001 > 0 &
                                    county %in% t_attri[,.N,by=county][N>10,]$county, 
                                  .(parcelfloodper, DP0230001, county),])
summary(housesize1)
plot(housesize1)
# Check fit values
t_attri[!(is.na(parcelfloodper) | is.na(DP0230001)) & DP0230001 > 0 &
          county %in% t_attri[,.N,by=county][N>10,]$county,][, housesize1_fit := meanBEINF(housesize1)] 
ggplot(t_attri, aes(x=housesize1_fit, y=parcelfloodper)) +
  geom_point() +
  geom_abline(slope=1, intercept=0)

ggplot(t_attri[!(is.na(parcelfloodper) | is.na(DP0230001)) & DP0230001 > 0,], aes(x=DP0230001, y=housesize1_fit)) +
  geom_point() +
  geom_abline(slope=1, intercept=0)


#Initial easy random effect model:
# --- % flooded population: zero-inflated zero regression
# --- Fixed effect (for now): average house price

#Initial more complex model:
# --- % flooded population: zero-inflated zero regression
# --- Fixed effect (for now): isometric log-ratio transformed race composition
# --- Random effect: county or watershed
#Potential implementations:
# --- GAMLSS (R package): generalized additive models for location, scale and shape
# --- JAGs (based on SEFS 590): mixture beta-bernoulli model with uninformative priors
# --- zoib (R package): bayesian approach



#+------------- Parcel-based regression analysis -------------
#https://stats.stackexchange.com/questions/259208/how-to-perform-isometric-log-ratio-transformation
#https://stats.stackexchange.com/questions/172905/bayesian-estimation-of-gee-models
# See van den Booqaart and Tolosana-Delgado (2013) - Analyzing Compositional Data with R
#     (sections 5.2 and 5.5 in particular for regression, advanced considerations and 7.1 for zeroes)
#---- Prepare data ----
BISG_cols <- c("white_BISG", "black_BISG", "hisp_BISG", "asi_BISG", "oth_BISG")
#p_regformat <- copy(p_attri) in final analysis if more RAM available
table(p_attri[last_pop>0, last_popflood/last_pop]) #Make sure that flood response is only 0-1
#Round data based on smallest values
p_attri[, sapply(.SD, function(x) min(ifelse(x>0, x, NA), na.rm=T)), .SDcols = BISG_cols]
p_attri[, (BISG_cols) := round(.SD, 6), .SDcols = BISG_cols]

#Make sure that race-ethnicity probability vector only sums to 0-1
#table(p_attri[, white_BISG+black_BISG+hisp_BISG+asi_BISG+oth_BISG]) 
p_attri[, sum_BISG := white_BISG + black_BISG + hisp_BISG + asi_BISG + oth_BISG]
p_attri[sum_BISG > 0, oth_BISG := oth_BISG + 1 - sum_BISG] %>%
  .[oth_BISG < 0, `:=`(white_BISG = white_BISG + oth_BISG,
                       oth_BISG = 0)] %>%
  .[white_BISG<0,`:=`(hisp_BISG = hisp_BISG + white_BISG,
                      white_BISG = 0)] %>%
  .[hisp_BISG<0,`:=`(black_BISG = black_BISG + hisp_BISG,
                     hisp_BISG = 0)]

#Deal with 0s by replacing them all by 10-6 through multiplicative imputation 
p_attri[sum_BISG > 0, (BISG_cols) := lapply(.SD, function(x){x[x==0] <- 10^(-6); x}), .SDcols = BISG_cols]
p_attri[, sum_BISG := white_BISG + black_BISG + hisp_BISG + asi_BISG + oth_BISG]
BISG_colsclo <- paste0(BISG_cols,"_clo")
p_attri[sum_BISG > 0, (BISG_colsclo) := lapply(.SD, `/`, sum_BISG), .SDcols = BISG_cols]
table(p_attri[, white_BISG_clo + black_BISG_clo + hisp_BISG_clo + asi_BISG_clo + oth_BISG_clo]) 

#Create compositional data
BISGcomp <- acomp(p_attri[!(sum_BISG %in% c(0, NA)), .SD, .SDcols = BISG_colsclo])

#Univariate histogram
colpal <- brewer.pal(n = length(BISG_colsclo), name="Set2")
uniBISG <- sapply(BISG_colsclo, function(cvar) {
  ggplotGrob(ggplot(p_attri, aes_string(x=cvar)) +
               geom_density(fill = colpal[which(BISG_colsclo == cvar)]) +
               scale_x_continuous(expand=c(0,0), name=cvar) +
               scale_y_sqrt() +
               theme_classic()
  )
})
do.call("grid.arrange", uniBISG)

#Make ternary density plots
ternmatrix_l <- sapply(seq_len(BISG_colsclo-1), function(i) {
  sapply(seq(2, BISG_colsclo), function(j) {
    if (i != j) {
      xpc <- BISG_colsclo[i]
      ypc <- BISG_colsclo[j]
      p_attri[!(sum_BISG %in% c(0, NA)), tern_oth_BISG := Reduce(`+`, .SD), .SDcols = BISG_colsclo[-c(i, j)]]
      nr <- nrow(p_attri[!(sum_BISG %in% c(0, NA)),]) 
      samp <- p_attri[!(sum_BISG %in% c(0, NA)),][sample(nr, nr/3),] 
      ggplotGrob(
        ggtern(data=samp,aes(get(xpc),get(ypc),tern_oth_BISG)) + 
          stat_density_tern(geom='polygon', aes(fill=..level..), bins=20, color=NA) + 
          scale_fill_distiller(palette='Spectral') + 
          theme(legend.position = 'none') +
          labs( x       = xpc,
                xarrow  = xpc,
                y       = ypc,
                yarrow  = ypc,
                z       = "Other",
                zarrow  = "Other") +
          theme_showarrows() + 
          theme_clockwise()
      )
    } 
  })
})  
do.call("grid.arrange", list(grobs=biplots_l[lower.tri(biplots_l, diag=T)], ncol=nPCs-1)) #only keep unique combinations


#Check whether % flooded is normally distributed by county and tracts

#---- creates generalized linear mixed-effect model with compositional data as independent variable ----
# See https://stats.idre.ucla.edu/other/mult-pkg/introduction-to-generalized-linear-mixed-models/ for GLMM theory and interpretation
# and https://stats.idre.ucla.edu/r/dae/mixed-effects-logistic-regression/ for logistic GLMM
subdt <- p_attri[county == '53077' & !(sum_BISG %in% c(0, NA)),]
BISGcomp_yakima <- acomp(subdt[, .SD, .SDcols = BISG_colsclo])

#Null model for AICc
pnull <- glmer(FloodStatus~ (1|GEOID10_t), data=subdt, family = binomial) 
summary(pnull)

#Mixed-effect model
p_glmemod <- glmer(FloodStatus~ilr(BISGcomp_yakima) + 1|GEOID10_t, 
              data=subdt, 
              family = binomial) 
summary(p_glmemod)
a = coef(p_glmemod)$GEOID10_t[,1] #p108
b = ilrInv(coef(p_glmemod)$GEOID10_t[1,-1],orig=BISGcomp_yakima)

#Create change matrix based on a set increase in race probability ratio
#ci,j in this case shows the increase in the response with a doubling of the ratio between the probability of i/probability of j
#e.g. the increase in the response if we go from 40% white/20% black to 80% white/20% black
change_mat <- matrix(NA, 5, 5)
rownames(change_mat) <- names(b)
colnames(change_mat) <- names(b)
coeflen <- length(b)
rc <- 2 #change in ratio bi/bj (see p14, Chastin et al. 2015, S2)
for (i in seq_len(coeflen)) {
  for (j in seq_len(coeflen)) {
    if (i==j) {
      change_mat[i,j] <- 0
    } else {
      change_mat[i,j] <- rc*(log2(b[i]/b[j])/4*coeflen^2)/2.78
    }
  }
}
#Exponentiating the change matrix gives us here specifically with a logistic regression the increase in odd ratios (very confusing)
change_mat_exp <- exp(change_mat) 

#Creating a matrix of new predictors spanning all values
predmat <- newprobmat(5)

#Add 10^06 to 0s and perform multiplicative reclosure
predmat_clo <- (predmat/100+10^-6)/rowSums(predmat/100+10^-6)

#Duplicate all probability combinations for each tract
ugeoid <- unique(subdt[, GEOID10_t])
tryl_geoid <- as.data.table(do.call(rbind, replicate(length(ugeoid), tryl, simplify=FALSE))) %>%
  cbind(rep(ugeoid, each=nrow(tryl)))
  
# calculate predicted probabilities and store in a list
acomp_pred <- acomp(predmat_clo[,1:5])
ilr(acomp_pred)
subdt[, trypred := predict(glmmod, type='response')]

ggplot(subdt, aes(x=white_BISG, y=trypred, color=GEOID10_t)) + 
  geom_point()

#blurg







