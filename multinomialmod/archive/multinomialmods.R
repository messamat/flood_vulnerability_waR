#Code by Ailene, ailene.ettinger@tnc.org
#Goal is to understand racial inequities in flood risk in Washington State

#housekeeping

rm(list=ls()) 
options(stringsAsFactors = FALSE)

#load libraries

library(sf)
library(data.table)
library(nnet)

#library(brms)

#Set working directory
rootdir<-"C:/Users/ailene.ettinger/Box/floodrisk/flood_vulnerability/flood_vulnerability"
datadir = file.path(rootdir, 'data')
resdir = file.path(rootdir, 'results')
figdir = file.path(resdir, 'figures')
gdb <- 'flood_risk.gdb'
setwd(resdir)

#Get data in format that we can use for models
p_attri <- st_read(dsn=gdb,layer="parcel_blocks_fill_flood_attri")#takes a long time to run!
p_attri <- setDT(p_attri)
p_attri <- p_attri[FEMAFloodStatus == 1 & is.na(FEMAStudyStatus), FEMAFloodStatus := 0]
p_attri <- p_attri[is.na(FEMAStudyStatus), FEMAStudyStatus := 0]

#To get county-unique code
p_attri[, county := as.factor(substr(GEOID10_t, 1, 5))]

#Subset to include only columns we care about
#PARCELPOP is the total pop in that parcel estimated by downscaling the census and the _BISG race probabilities are average probability distributions across all inhabitants of parcel (e.g. in the case of a condo building with lots of owners)

p_attri_subcol <- p_attri[last_pop>0, .(PolyID, FloodStatus, county,PARCELPOP, last_pop, white_BISG, black_BISG, hisp_BISG, asi_BISG, oth_BISG)]
# head(p_attri)
# head(p_attri_subcol)
# unique(round(p_attri_subcol$white_BISG, digits=1))
# hist(p_attri_subcol$white_BISG)
# hist(p_attri_subcol$black_BISG)
#hist(p_attri_subcol$FloodStatus)
#range(p_attri_subcol$PARCELPOP)

#p_attri_subcol<-p_attri_subcol[p_attri_subcol$parcelpop.int>0,]#pop must be greater than 0...

unique(p_attri_subcol$county)#39 levels, but some have no data (counties 53065, 53075, 53031, 53015, 53041, 53055 (is.na)
cty<-tapply(p_attri_subcol$PARCELPOP,list(p_attri_subcol$county),length)
remove.cty<-c(names(cty[which(is.na(cty))]),names(cty[which(cty<100)]))
d %>% filter(!(remove.cty, county))
df %>% filter(!grepl(remove.cty, county))
#Try limiting to just one county or a few counties to try to get model running? Trouble shooting is taking a while...
#p_53001<-p_attri_subcol[p_attri_subcol$county==53001,]
#p_5count<-p_attri_subcol[p_attri_subcol$county==53001|p_attri_subcol$county==53003|p_attri_subcol$county==53005|p_attri_subcol$county==53047|p_attri_subcol$county==53019,]
#dim(p_5count)#72706    10


#d<-as.data.frame(p_53001)#single county test dataset
d<-as.data.frame(p_attri_subcol)#whole state dataset
d<-d[d$county==remcty,]
#save this dataframe in case its useful later
write.csv(d,"output/datallcnty.csv", row.names= FALSE)

#Convert proportions of race to integers, as some packages (e.g. brms, nnet) use this format

white_int<-as.integer(d$white_BISG*d$PARCELPOP)
black_int<-as.integer(d$black_BISG*d$PARCELPOP)
hisp_int<-as.integer(d$hisp_BISG*d$PARCELPOP)
asi_int<-as.integer(d$asi_BISG*d$PARCELPOP)
oth_int<-as.integer(d$oth_BISG*d$PARCELPOP)
d$parcelpop.int<-as.integer(white_int+black_int+hisp_int+asi_int+oth_int)

#Summarize and Aggregate data by county
ctywh<-aggregate(white_int, by=list(d$county,d$FloodStatus), sum)
ctybl<-aggregate(black_int, by=list(d$county,d$FloodStatus), sum)
ctyhi<-aggregate(hisp_int, by=list(d$county,d$FloodStatus), sum)
ctyasi<-aggregate(asi_int, by=list(d$county,d$FloodStatus), sum)
ctyoth<-aggregate(oth_int, by=list(d$county,d$FloodStatus), sum)
ctyall<-cbind(ctywh,ctybl$x,ctyhi$x,ctyasi$x,ctyoth$x)
colnames(ctyall)<-c("county","flood.status","white_tot","black_tot","hisp_tot","asi_tot","oth_tot")
ctyall$tot<-as.integer(ctyall$white_tot+ctyall$black_tot+ctyall$hisp_tot+ctyall$asi_tot+ctyall$oth_tot)

#Calculate proportions from data, to compare to model estimates later
ctyall$white<-ctyall$white_tot/ctyall$tot
ctyall$black<-ctyall$black_tot/ctyall$tot
ctyall$hisp<-ctyall$hisp_tot/ctyall$tot
ctyall$asi<-ctyall$asi_tot/ctyall$tot
ctyall$oth<-ctyall$oth_tot/ctyall$tot
ctyall<-ctyall[-51,]

write.csv(ctyall,"output/countysum_byrace.csv")

#Create multinomial response variable for model fitting
d$y <- with(d, cbind(white_int,black_int, hisp_int,asi_int,oth_int))
head(d)
tail(d)
dim(d)
d<-d[d$parcelpop.int>0,]#pop must be greater than 0 to include in modelling
d$county<-as.factor(d$county)
dim(d)

#Fit multinomial model with nnet
#a useful website for nnet https://data.princeton.edu/wws509/r/c6s2

m<-multinom(y~FloodStatus*county,dat=d)

#Look at predicted probabilities
preds<-as.data.frame(predict(m, d,"probs"))
colnames(preds)<-c("white_pred","black_pred","hisp_pred","asi_pred","oth_pred")
dim(preds)
ctywh<-aggregate(preds$white_pred, by=list(d$county,d$FloodStatus), mean)
ctybl<-aggregate(preds$white_pred, by=list(d$county,d$FloodStatus), mean)
ctyhi<-aggregate(preds$white_pred, by=list(d$county,d$FloodStatus), mean)
ctyasi<-aggregate(preds$white_pred, by=list(d$county,d$FloodStatus), mean)
ctyoth<-aggregate(preds$white_pred, by=list(d$county,d$FloodStatus), mean)
ctyallpreds<-cbind(ctywh,ctybl$x,ctyhi$x,ctyasi$x,ctyoth$x)
colnames(ctyallpreds)<-c("county","flood.status","white","black","hisp","asi","oth")

#save predicted proportions by county
write.csv(ctyallpreds,"output/countypredsnnet.csv")

#Need to do some model comparisons (e.g., to null model to evaluate significance of flood status and county differences)

#compare calculated probs vs fitting probs

png("predvsobs.nnet.png",width = 800, height = 400)
par(mfrow=c(2,3))
cols<-c("white","black","hisp","asi","oth")
for(i in 1:5){
  datcol<-which(colnames(ctyall)==cols[i])
  predcol<-which(colnames(ctyallpreds)==cols[i])
  plot(ctyall[,datcol],ctyallpreds[,predcol],xlab="observed",ylab="predicted", main=paste(cols[i]))
}
dev.off()
mod<-lm(ctyallpreds$white~ctyall$white_prop)
abline(mod)
paste()
#Various other attemps, most of which did not work well! Saving the code in case we want to try anything again...
#not multilevel version
library(mclogit)
#this package didn't yield good estimates- large errors, multilevel version did not converge
#because our dataset is so large, models are really struggling to accomdate all this data. I'm not sure how to deal with this...
#For now, I will randomly sample 25 of the data and try that

dquart<-d[sample(nrow(d),round(nrow(d)/4,digits=0)),]
m<-mblogit(y~FloodStatus*county,dat=dquart)

summary(m)#hispanic and other higher in flooded areas compared to whites. blacks and 
dim(predict(m))
unique(predict(m, d,"response"))  
#white_int  black_int   hisp_int    asi_int     oth_int
#[1,] 0.8137231 0.04745123 0.06420777 0.06887423 0.005743656#not flooded
#[2,] 0.7790506 0.02850946 0.15887252 0.02201120 0.011556192#flooded
png("muplot.png",width = 400, height = 800)
#par(mar=c(5,7,3,10))

xlim=c(-1.5,1.5)
ylim=c(0,5)
modrace<-rev(c("black","hisp","asian","other"))
plot(x=NULL,y=NULL, xlim=xlim, yaxt='n', ylim=ylim, xlab="Estimated relative change in presence, with flooding (compared to whites)", ylab="")
axis(2, at=1:4, labels=modrace, las=1)
abline(v=0, lty=2, col="darkgrey")
se<-summary(m)$coef[5:8,2]
for(i in 1:4){
  pos.y<-(4:1)[i]
  pos.x<-summary(m)$coef[4+i,1]
  lines(c(pos.x+se[i],pos.x-se[i]),rep(pos.y,2),col="darkgrey")
  points(pos.x,pos.y,cex=1.5,pch=19,col="darkblue")
}
dev.off()
for(spsi in 1:spnum){
  pos.sps.i<-which(grepl(paste("[",spsi,"]",sep=""),rownames(summary(modelhere)$summary),fixed=TRUE))[2:4]
  jitt<-runif(1,0.05,0.4)
  pos.y.sps.i<-pos.y-jitt
  pos.x.sps.i<-summary(modelhere)$summary[pos.sps.i[i],"mean"]
  lines(summary(modelhere)$summary[pos.sps.i[i],c("25%","75%")],rep(pos.y.sps.i,2),
        col=alpha(my.pal[spsi], alphahere))
  points(pos.x.sps.i,pos.y.sps.i,cex=0.8, pch=my.pch[spsi], col=alpha(my.pal[spsi], alphahere))
  
}

dev.off()


#Plot
coef(m)

mm2<-mblogit(y~FloodStatus, random = ~FloodStatus|county,dat=d,control = mclogit.control(epsilon = 1e-08, maxit = 1000, trace = TRUE))
#tried range of max it from 25-1000: didn't converge ever
#tried decreasing epsilon (1e08, 1e05)
summary(mm2)
predict(mm)#does not work! not sure why
unique(predict(mm, d,"response"))#does not work  
fitted.values(mm)

#compare mm v m
plot(fitted.values(m),fitted.values(mm))#MAny of these differ substantially....likely do to differences in county-level estimates

#Possible approaches:
#1) Fit separate model for each county. compare plots of county-level estimates by race (i.e. logodds of being in a flood )
#2) Try a different package (mlogit)

#time to try mlogit!
library(mlogit)
#Some example datasets from the package vignette
## Cameron and Trivedi's Microeconometrics p.493 There are two
## alternative specific variables : price and catch one individual
## specific variable (income) and four fishing mode : beach, pier, boat,
## charter
data("Fishing", package = "mlogit")

Fish <- mlogit.data(Fishing, varying = c(2:9), shape = "wide", choice = "mode")
## a pure "conditional" model
summary(mlogit(mode ~ price + catch, data = Fish))
## a pure "multinomial model"
summary(mlogit(mode ~ 0 | income, data = Fish))
## a "mixed" model
m <- mlogit(mode ~ price+ catch | income, data = Fish)
summary(m)
## same model with charter as the reference level
m <- mlogit(mode ~ price+ catch | income, data = Fish, reflevel = "charter")
## same model with a subset of alternatives : charter, pier, beach
m <- mlogit(mode ~ price+ catch | income, data = Fish,
            alt.subset = c("charter", "pier", "beach"))
## model on unbalanced data i.e. for some observations, some
## alternatives are missing
# a data.frame in wide format with two missing prices
Fishing2 <- Fishing
Fishing2[1, "price.pier"] <- Fishing2[3, "price.beach"] <- NA
mlogit(mode~price+catch|income, Fishing2, shape="wide", choice="mode", varying = 2:9)




d3<-subset(d,select=c(white_BISG,black_BISG,hisp_BISG,asi_BISG,oth_BISG,FloodStatus,PolyID,county))
d3$white_BISG<-as.integer(d3$white_BISG)
d3$black_BISG<-as.integer(d3$black_BISG)
d3$hisp_BISG<-as.integer(d3$hisp_BISG)
d3$asi_BISG<-as.integer(d3$asi_BISG)
d3$oth_BISG<-as.integer(d3$oth_BISG)
colnames(d3)[1:5]<-c("y.white_int","y.black_int","y.hisp_int","y.asi_int","y.oth_int")
d2<-subset(d,select=c(y,FloodStatus,PolyID,county))

d.mlogit <- reshape(d3, direction = "long", varying = list(colnames(d3)[1:5]),v.names = "number", idvar = "PolyID", times = c("white","black","hisp","asi","oth"),timevar= "race")
head(d.mlogit)
d.mlogit<-d.mlogit[order(d.mlogit$PolyID),]
ml <- mlogit(number ~ FloodStatus,id.var=PolyID,alt.var=time,dat=d.mlogit)


####Simulating data to test the models out

#simulate some data to test a model
N <- 15
flooddat <- data.frame(
  y1 = rbinom(N, 10, 0.3), 
  y2 = rbinom(N, 10, 0.3),
  y3 = rbinom(N, 10, 0.6), #higher risk of floofing
  x = rnorm(N)
)

flooddat$y <- with(flooddat, cbind(y1, y2, y3))
flooddat$size <- with(flooddat, y1 + y2 + y3)
flooddat$status<-1
nonflooddat <- data.frame(
  y1 = rbinom(N, 10, 0.3), 
  y2 = rbinom(N, 10, 0.3), 
  y3 = rbinom(N, 10, 0.3), 
  x = rnorm(N)
)
nonflooddat$y <- with(nonflooddat, cbind(y1, y2, y3))
nonflooddat$size <- with(nonflooddat, y1 + y2 + y3)
nonflooddat$status<-0

#dat<-flooddat
dat<-rbind(flooddat,nonflooddat)


#Test modelusing the nnet package

n <- 1000
df1 <- data.frame(x1=runif(n,0,100),
                  x2=runif(n,0,100))
df1 <- transform(df1,
                 y=1+ifelse(100 - x1 - x2 + rnorm(n,sd=10) < 0, 0,
                            ifelse(100 - 2*x2 + rnorm(n,sd=10) < 0, 1, 2)),
                 set="Original")

mod <- multinom(y ~ x1 + x2, df1)

predict(mod)
predict(mod,df1,"probs")
#now try with my simulated flood data
mod2 <- multinom(y ~ status, dat)
predict(mod2, dat,"probs")  

library(mclogit)

m1<-mclogit(y ~ status, dat=dat)
m2<-mblogit(y~status,dat=dat)
summary(m2)
summary(m1)
predict(m2)

#try clmm2 from ordinal package
library(ordinal)
mod2 <- clmm(y ~ status, dat=dat)
#y has to be factors for this package- I don't want to do that if possible! will make our dataset even bigger!
#i don't think nnet has multilevel mods
#what about library("mlogit")
#useful link for this package is library("mlogit")


