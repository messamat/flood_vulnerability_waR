#Code by Ailene, ailene.ettinger@tnc.org
#Started Feb 2020
#Goal is to understand racial inequities in flood risk in Washington State
#Bayesian approach via brms
#housekeeping

rm(list=ls()) 
options(stringsAsFactors = FALSE)

library(sf)
library(data.table)
library("brms")
library("rstan")
options(mc.cores = parallel::detectCores())

#rstan_options(auto_write = TRUE)
#which allows you to automatically save a bare version of a compiled Stan program to the hard disk so that it does not need to be recompiled (unless you change it).

#Finally, if you use Windows, there will be a third startup message saying to execute, only if no c++ chain run previously...
#Sys.setenv(LOCAL_CPPFLAGS = '-march=corei7')# should be unnecessary

rootdir<-"C:/Users/ailene.ettinger/Box/research/flood_vulnerability"
datadir = file.path(rootdir, 'data')
resdir = file.path(rootdir, 'results/')
figdir = file.path(resdir, 'figures/')
gdb <- 'flood_risk.gdb'
setwd(resdir)
p_attri <- st_read(dsn=gdb,layer="parcel_blocks_fill_flood_attri")#takes a long time to run!
p_attri <- setDT(p_attri)
p_attri <- p_attri[FEMAFloodStatus == 1 & is.na(FEMAStudyStatus), FEMAFloodStatus := 0]
p_attri <- p_attri[is.na(FEMAStudyStatus), FEMAStudyStatus := 0]

#To get county-unique code
p_attri[, county := as.factor(substr(GEOID10_t, 1, 5))]

#The columns that you want (and subset so that it only includes parcels with population that includes private owner's last name information - last_pop)
#PARCELPOP is the total pop in that parcel estimated by downscaling the census and the _BISG race probabilities are average probability distributions across all inhabitants of parcel (e.g. in the case of a condo building with lots of owners)

p_attri_subcol <- p_attri[last_pop>0, .(PolyID, FloodStatus, county,PARCELPOP, last_pop, white_BISG, black_BISG, hisp_BISG, asi_BISG, oth_BISG)]

# head(p_attri)
# head(p_attri_subcol)
# unique(round(p_attri_subcol$white_BISG, digits=1))
# hist(p_attri_subcol$white_BISG)
# hist(p_attri_subcol$black_BISG)
#hist(p_attri_subcol$FloodStatus)
#range(p_attri_subcol$PARCELPOP)


#p_attri_subcol<-p_attri_subcol[p_attri_subcol$parcelpop.int>0,]#pop must be greater than 0...

#Try limiting to just one county or a few counties to try to get model running? Trouble shooting is taking a while...
unique(p_attri_subcol$county)#39 levels
p_53001<-p_attri_subcol[p_attri_subcol$county==53001,]

p_5count<-p_attri_subcol[p_attri_subcol$county==53001|p_attri_subcol$county==53003|p_attri_subcol$county==53005|p_attri_subcol$county==53047|p_attri_subcol$county==53019,]
dim(p_5count)#72706    10
tapply(p_attri_subcol$PARCELPOP,list(p_attri_subcol$county),length)

#Convert proportions to integers


#d<-as.data.frame(p_53001)#single county test dataset
d<-as.data.frame(p_attri_subcol)#whole state dataset
#will need to remove 53031 perhaps- only 5 rows of data. other counties?
cnty.na<-names(which(is.na(tapply(d$PARCELPOP,list(d$county),length))))
cnty.littledata<-names(which(tapply(d$PARCELPOP,list(d$county),length)<100))
cnty.probmodests<-c(53019,53039,53023, 53069)
#remove 53065, 53075, 53031, 53015, 53041, 53055 (is.na and <100)
cnty.to.remove<-c(cnty.na,cnty.littledata,cnty.probmodests)

d<-d[!(d$county %in% cnty.to.remove),]
#d<-as.data.frame(p_5count)#picked 5 counties
white_int<-as.integer(d$white_BISG*d$PARCELPOP)
black_int<-as.integer(d$black_BISG*d$PARCELPOP)
hisp_int<-as.integer(d$hisp_BISG*d$PARCELPOP)
asi_int<-as.integer(d$asi_BISG*d$PARCELPOP)
oth_int<-as.integer(d$oth_BISG*d$PARCELPOP)
d$parcelpop.int<-as.integer(white_int+black_int+hisp_int+asi_int+oth_int)
d$y <- with(d, cbind(white_int,black_int, hisp_int,asi_int,oth_int))
head(d)
tail(d)
dim(d)
d<-d[d$parcelpop.int>0,]#pop must be greater than 0...
d$county<-factor(d$county)#29levels 
cnty<-unique(d$county)
tapply(d$PARCELPOP,list(d$county),length)

#dim(d)#1683683 rows
#First fit model without county as a level:
#mod <- brm(bf(y | trials(parcelpop.int)  ~ 1), data = d, 
#           family = multinomial())#intercept only model- just to see if it fits! it does! takes about 8 minutes for one county...

#Fit a separate model for each county!
for(c in 1:length(cnty)){
cd<-d[d$county==cnty[c],]
cdsum<-cbind(aggregate(cd$white_BISG,by=list(cd$FloodStatus), sum),
             aggregate(cd$black_BISG,by=list(cd$FloodStatus), sum)[,2],
             aggregate(cd$hisp_BISG,by=list(cd$FloodStatus), sum)[,2],
             aggregate(cd$asi_BISG,by=list(cd$FloodStatus), sum)[,2],
             aggregate(cd$oth_BISG,by=list(cd$FloodStatus), sum)[,2])
colnames(cdsum)<-c("FloodStatus","white","black","hisp","asi","oth")
savedatsum<-paste(resdir,"/brmsmodresults/datsum",cnty[c],".csv", sep="")
write.csv(cdsum,file=savedatsum)

mod2 <- brm(bf(y | trials(parcelpop.int)  ~ FloodStatus), data = cd, 
            family = multinomial(), 
            iter=3000,warmup = 1500, chains = 2, control = list(adapt_delta = 0.99, max_treedepth = 15))##options(MC.cores=parallel::detectCores())
savemod<- paste(resdir,"/brmsmodresults/brmsmod",cnty[c],".RData", sep="")
save(mod2,file=savemod)
savecoefs<- paste(resdir,"/brmsmodresults/brmscoef",cnty[c],".csv", sep="")
write.csv(fixef(mod2),file=savecoefs)
}


#Now, lump some racial groups together to see if model fits better!
casioth<-c(53019,53039)#counties for which we should lump asians with other categoriy to get estimates

for(c in 1:length(casioth)){
  cd<-d[d$county==casioth[c],]
  #Code to lump 2 groups
  ######ADD HERE
  cd$oth<-
    
  cdsum<-cbind(aggregate(cd$white_BISG,by=list(cd$FloodStatus), sum),
               aggregate(cd$black_BISG,by=list(cd$FloodStatus), sum)[,2],
               aggregate(cd$hisp_BISG,by=list(cd$FloodStatus), sum)[,2],
               aggregate(cd$asi_BISG,by=list(cd$FloodStatus), sum)[,2],
               aggregate(cd$oth_BISG,by=list(cd$FloodStatus), sum)[,2])
  colnames(cdsum)<-c("FloodStatus","white","black","hisp","asi","oth")
  savedatsum<-paste(resdir,"/brmsmodresults/datsum",cnty[c],".csv", sep="")
  write.csv(cdsum,file=savedatsum)
  
  mod2 <- brm(bf(y | trials(parcelpop.int)  ~ FloodStatus), data = cd, 
              family = multinomial(), 
              iter=3000,warmup = 1500, chains = 2, control = list(adapt_delta = 0.99, max_treedepth = 15))##options(MC.cores=parallel::detectCores())
  savemod<- paste(resdir,"/brmsmodresults/brmsmod",cnty[c],".RData", sep="")
  save(mod2,file=savemod)
  savecoefs<- paste(resdir,"/brmsmodresults/brmscoef",cnty[c],".csv", sep="")
  write.csv(fixef(mod2),file=savecoefs)
}
#load(paste(resdir,"/brmsmodresults/brmsmod53019.RData", sep=""))#options(MC.cores=parallel::detectCores())
#load(paste(resdir,"/brmsmodresults/brms
#mod53061.RData", sep=""))#options(MC.cores=parallel::detectCores())

plot(mod)
p<-conditional_effects(mod, categorical=TRUE)
summary(mod)
fixef(mod)#Look at data for cnty
cnty

#Do the same thing at the tract level
# #Read census tract-level data
# #Read census tract-level data
t_attri <- st_read(dsn=gdb, layer="tracts_floodfinal")
t_attri <- setDT(t_attri)
t_attri[, county := as.factor(substr(GEOID10_t, 1, 5))]


#The columns that you want (and subset so that it only includes parcels with population that includes private owner's last name information - last_pop)
#PARCELPOP is the total pop in that parcel estimated by downscaling the census and the _BISG race probabilities are average probability distributions across all inhabitants of parcel (e.g. in the case of a condo building with lots of owners)

t_attri_subcol <- t_attri[SUM_last_pop>0, .(GEOID10, parcelfloodper, county,SUM_last_pop, white_BISG_per, black_BISG_per, hisp_BISG_per, asi_BISG_per, oth_BISG_per)]


t<-as.data.frame(t_attri_subcol)#whole state dataset
#will need to remove 53031 perhaps- only 5 rows of data. other counties?
cnty.na<-names(which(is.na(tapply(t$SUM_last_pop,list(t$county),length))))
cnty.littledata<-names(which(tapply(t$SUM_last_pop,list(t$county),length)<5))

cnty.to.remove<-c(cnty.na,cnty.littledata)

t<-t[!(t$county %in% cnty.to.remove),]
#d<-as.data.frame(p_5count)#picked 5 counties
white_int<-as.integer(t$white_BISG*t$SUM_last_pop)
black_int<-as.integer(t$black_BISG*t$SUM_last_pop)
hisp_int<-as.integer(t$hisp_BISG*t$SUM_last_pop)
asi_int<-as.integer(t$asi_BISG*t$SUM_last_pop)
oth_int<-as.integer(t$oth_BISG_per*t$SUM_last_pop)
t$parcelpop.int<-as.integer(white_int+black_int+hisp_int+asi_int+oth_int)
t$y <- with(t, cbind(white_int,black_int, hisp_int,asi_int,oth_int))
head(t)
tail(t)
dim(t)
t<-t[t$SUM_last_pop>0,]#pop must be greater than 0...
t$county<-factor(t$county)#33 levels 
cnty<-unique(t$county)
tapply(t$SUM_last_pop,list(t$county),length)

#Fit a separate model for each county!
for(c in 1:length(cnty)){
  cd<-t[t$county==cnty[c],]
  mod <- brm(bf(y | trials(parcelpop.int)  ~parcelfloodper), data = cd, 
              family = multinomial(), 
              iter=3000,warmup = 1500, chains = 2, control = list(adapt_delta = 0.99, max_treedepth = 15))##options(MC.cores=parallel::detectCores())
  savemod<- paste(resdir,"/brmsmodresults/brmsmodtract",cnty[c],".RData", sep="")
  save(mod,file=savemod)
  savecoefs<- paste(resdir,"/brmsmodresults/brmscoeftract",cnty[c],".csv", sep="")
  write.csv(fixef(mod),file=savecoefs)
  print(summary(mod))
}

#Fit a model to the whole state to get overall effects
#restrict to only counties for which we were able to get good model fits
p<-read.csv("results/brmsmodresults/countyests.csv")

p$muasiint_FloodStatus..SE.[which(p$muasiint_FloodStatus..SE.>2)]<-NA
p$mublackint_FloodStatus..SE.[which(p$mublackint_FloodStatus..SE.>2)]<-NA
p$muhispint_FloodStatus..SE.[which(p$muhispint_FloodStatus..SE.>2)]<-NA
p$muothint_FloodStatus..SE.[which(p$muothint_FloodStatus..SE.>2)]<-NA
p$muasiint_FloodStatus[which(p$muasiint_FloodStatus..SE.>2)]<-NA
p$mublackint_FloodStatus[which(p$mublackint_FloodStatus..SE.>2)]<-NA
p$muhispint_FloodStatus[which(p$muhispint_FloodStatus..SE.>2)]<-NA
p$muothint_FloodStatus[which(p$muothint_FloodStatus..SE.>2)]<-NA



#Old Models
# mod1 <- brm(bf(y | trials(parcelpop.int)  ~ FloodStatus*county), data = d, 
#             family = multinomial(), iter=500, chains=1)#includes flood status, runs very slowly...seeing seeing how long it will take for the full dataset to run!
# 
# mod2 <- brm(bf(y | trials(parcelpop.int)  ~ FloodStatus), data = d, 
#             family = multinomial())#includes flood status, runs very slowly...seeing seeing how long it will take for the full dataset to run!
# #This takes a very long time...4766.48 seconds for  one chain. 
# #model has many divergent transitions and other issues. likely not a lot of information for some races...this may be a problem...
# 

#Next try to fit to whole dataset with random effect of county
# 
# mod3 <- brm(bf(y | trials(parcelpop.int)  ~ FloodStatus + (1|county)), data = d, 
#             family = multinomial(),iter=500, chains=2,
#             prior=c(set_prior ("normal (0, 1)")))
# 
# 
# plot(mod3)
# conditional_effects(mod3, categorical=TRUE)
# summary(mod3)
# #started at 9:22pm on March 28, 2020
# mod4 <- brm(bf(y | trials(parcelpop.int)  ~ FloodStatus + (FloodStatus|county)), data = d, 
#             family = multinomial(),iter=500, chains=2,
#             prior=c(set_prior ("normal (0, 2)")))
# 
# 
# plot(mod4)
# conditional_effects(mod4, categorical=TRUE)
# summary(mod4)

#(1 | ID1 | state) + (1 | ID2 | state:county) + (1 | ID3 | state:county:zip)
#Questions: Should we:

#

####Simulating data to test the model out

N <- 15
flooddat <- data.frame(
  y1 = rbinom(N, 10, 0.3), 
  y2 = rbinom(N, 10, 0.3),
  y3 = rbinom(N, 10, 0.6), #higher risk of floofing
  x = rnorm(N)
)

flooddat$y <- with(flooddat, cbind(y1, y2, y3))
flooddat$size <- with(flooddat, y1 + y2 + y3)
flooddat$status<-1
nonflooddat <- data.frame(
  y1 = rbinom(N, 10, 0.3), 
  y2 = rbinom(N, 10, 0.3), 
  y3 = rbinom(N, 10, 0.3), 
  x = rnorm(N)
)
nonflooddat$y <- with(nonflooddat, cbind(y1, y2, y3))
nonflooddat$size <- with(nonflooddat, y1 + y2 + y3)
nonflooddat$status<-0

#dat<-flooddat
dat<-rbind(flooddat,nonflooddat)

summary(fit3)
fit4 <- brm(bf(y | trials(size)  ~ status), data = dat, 
            family = multinomial(), prior=c(set_prior ("normal (0, 8)")))
summary(fit4)
conditional_effects(fit4, categorical=TRUE)
p_attri_subcol<-as.data.frame(p_attri_subcol)